{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHORTCUTS\n",
    "    #ShiftEnter run current cell and move to the next\n",
    "    #CtrlEnter run current cell\n",
    "    #Ctrl/ toggle commenting of line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done adjusting...\n"
     ]
    }
   ],
   "source": [
    "#so that notebook fills screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "print(\"Done adjusting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Welcome to the demo/tutorial for Joe Faraguna's Python pipeline for MS/phenotypic data analysis! \n",
    "#The code I've written for the pipeline is contained within 2 python files, classes.py and modules.py\n",
    "    #classes contains information about the structure of the Experiments that you can create and handles adding replicates and calling analysis or plot functions on your data\n",
    "    #modules contains more basic functions that are called by the functions within classes - classes shuttles most of the analysis to modules and then returns it to the user\n",
    "#As a user, you will not be interacting with most of the code in either of these two files\n",
    "    \n",
    "#As a user, the general workflow is:\n",
    "    #1) LOAD DATA - specify where your csv files are that store MS data, specify cell lines names and time points\n",
    "    #2) CREATE EXPERIMENT - relate this data to an Experiment, a data structure represented in classes.py\n",
    "    #3) RUN ANALYSIS - call Experiment functions to generate plots and files\n",
    "\n",
    "\n",
    "#You need to import these every time you want to run the pipeline\n",
    "import classes\n",
    "import modules\n",
    "#This is a visualization package for plotting graphs in python. It is also required.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Done importing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) LOAD DATA\n",
    "\n",
    "#Now that we've installed the pipeline and a plotting package, we have to load our data (I'm using Jacqueline's Gerritsen's MS data on EGFR tyrosine point-mutation mutants here).\n",
    "#Here, we begin with MS data, although we can also load phenotypic data\n",
    "\n",
    "#locations is a list of lists\n",
    "    #each list stores the locations of all the .csv files for one experimental replicate\n",
    "#in this case, we have 3 experimental replicates with 8 cell lines each: 2934, 2935, 2936, 2937, 2938, 3126, 3127, and 3138\n",
    "\n",
    "#NOTE: each experimental replicate includes the cell line data in the same order\n",
    "#NOTE: the pipeline assumes the last cell line, in this case 3138, is the reference cell line (wt, untreated, etc, in this case WT EGFR receptor), although this can be changed later\n",
    "locations = [\n",
    "\t[\"demo/input/ms/2934_2nM_BR1.csv\",\n",
    "\t\"demo/input/ms/2935_2nM_BR1.csv\",\n",
    "\t\"demo/input/ms/2936_2nM_BR1.csv\",\n",
    "\t\"demo/input/ms/2937_2nM_BR1.csv\",\n",
    "\t\"demo/input/ms/2938_2nM_BR1.csv\",\n",
    "\t\"demo/input/ms/3126_2nM_BR1.csv\",\n",
    "\t\"demo/input/ms/3127_2nM_BR1.csv\",\n",
    "\t\"demo/input/ms/3138_2nM_BR1.csv\"],\n",
    "\t[\"demo/input/ms/2934_2nM_BR2.csv\",\n",
    "\t\"demo/input/ms/2935_2nM_BR2.csv\",\n",
    "\t\"demo/input/ms/2936_2nM_BR2.csv\",\n",
    "\t\"demo/input/ms/2937_2nM_BR2.csv\",\n",
    "\t\"demo/input/ms/2938_2nM_BR2.csv\",\n",
    "\t\"demo/input/ms/3126_2nM_BR2.csv\",\n",
    "\t\"demo/input/ms/3127_2nM_BR2.csv\",\n",
    "\t\"demo/input/ms/3138_2nM_BR2.csv\"],\n",
    "\t[\"demo/input/ms/2934_2nM_BR3.csv\",\n",
    "\t\"demo/input/ms/2935_2nM_BR3.csv\",\n",
    "\t\"demo/input/ms/2936_2nM_BR3.csv\",\n",
    "\t\"demo/input/ms/2937_2nM_BR3.csv\",\n",
    "\t\"demo/input/ms/2938_2nM_BR3.csv\",\n",
    "\t\"demo/input/ms/3126_2nM_BR3.csv\",\n",
    "\t\"demo/input/ms/3127_2nM_BR3.csv\",\n",
    "\t\"demo/input/ms/3138_2nM_BR3.csv\"]]\n",
    "#Open pipeline/demo/input/ms/2934_2nM_BR1.csv to see the structure of these files\n",
    "    #The first two columns are the peptide sequences and protein descriptions from MS analysis\n",
    "        #Keep the full protein description (OX = ... GN = ...) because the pipeline will sometimes display GNs for short\n",
    "    #The next n columns are peptide abundance measurements that have been filtered for high confidence\n",
    "        #and normalized to the SUP channel so that different runs can be compared.\n",
    "    #Including the header row with titles is required, although the names of the columns will be written over by the pipeline\n",
    "        #However, the n columns of abundance measurements should be in time order\n",
    "\n",
    "#We can also load technical replicates, which will be combined differently than experimental ones\n",
    "technicalReplicate = [\"demo/input/ms/2934_2nM_BR2TR.csv\",\n",
    "\t\"demo/input/ms/2935_2nM_BR2TR.csv\",\n",
    "\t\"demo/input/ms/2936_2nM_BR2TR.csv\",\n",
    "\t\"demo/input/ms/2937_2nM_BR2TR.csv\",\n",
    "\t\"demo/input/ms/2938_2nM_BR2TR.csv\",\n",
    "\t\"demo/input/ms/3126_2nM_BR2TR.csv\",\n",
    "\t\"demo/input/ms/3127_2nM_BR2TR.csv\",\n",
    "\t\"demo/input/ms/3138_2nM_BR2TR.csv\"]\n",
    "#Open pipeline/demo/input/ms/2934_2nM_BR2TR.csv to see the structure of these files\n",
    "    #These are structured the same as MS replicate data\n",
    "\n",
    "#We can also load phenotypic data replicates.\n",
    "phenotypicMeasurement = ['demo/input/ph/PhenoClass 1.csv',\n",
    "\t'demo/input/ph/PhenoClass 3.csv',\n",
    "\t'demo/input/ph/PhenoClass 4.csv']\n",
    "#Open pipeline/demo/input/ph/PhenoClass1.csv to see the structure of these files\n",
    "    #The two columns are Cell Line and a numerical replicate identifier column (e.g. 1, 2...)\n",
    "    #Each phenotypic replicate should have one measurement per cell line\n",
    "    #Including the hreader row with Cell Line and a numerical replicate identifier is required\n",
    "\n",
    "#Finally, we have to include information about the names of the cell lines and the time points we gather MS data at\n",
    "cell_lines = ['2934','2935','2936','2937','2938','3126','3127','3138']\n",
    "time_points = [0, 30, 1, 2, 5]\n",
    "second_time_points = [0, 30, 60, 120, 300]\n",
    "\n",
    "print(\"Done listing data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) CREATE EXPERIMENT\n",
    "\n",
    "#Now that we've listed the file locations, cell line names, and time points, we can create the Experiment.\n",
    "#The pipeline is built around Experiments, which is a structure for organizing MS and phenotypic data about related cell lines and for analyzing and plotting the data.\n",
    "    #More on this later.\n",
    "    \n",
    "#creates experiment for all 3 replicates\n",
    "exp = classes.Experiment(locations, cell_lines, time_points, second_time_points, names = [\"BR1\", \"BR2\", \"BR3\"], fileLocation = 'demo/output/')\n",
    "\n",
    "#creates experiment for BR1 and BR2, not BR3\n",
    "exp2 = classes.Experiment([locations[0],locations[1]], cell_lines, time_points, second_time_points, names = [\"BR1\", \"BR2\"], fileLocation = 'demo/output/')\n",
    "\n",
    "#We also specified a fileLocation for the Experiment: this is the default location for saving plots and Excel files that we generate, although we can override it whenever we call a plotting function.\n",
    "\n",
    "#We can call print() on the experiments to check that everything loaded correctly. Doing this will display information about each MS data replicate within the Experiment.\n",
    "    #This includes the number of peptides for each cell line as well as the number of peptides that overlap between all cell lines for that given replicate.\n",
    "print(\"~~~EXPERIMENT 1~~~\")\n",
    "print(exp)\n",
    "print(\"\\n~~~EXPERIMENT 2~~~\")\n",
    "print(exp2)\n",
    "\n",
    "#Notice that exp2 is just exp except without the 3rd replicate, BR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also add the technical replicate to exp while we're at it\n",
    "#The technical replicate was made along with BR2, so let's add it to BR2\n",
    "    #Since Python is 0-indexed, we say i=1 because our replicates are [BR1, BR2, BR3]\n",
    "exp.addTechnicalReplicate(technicalReplicate,i = 1)\n",
    "#Notice that BR2 now has a lot more peptide data than before, although BR1 and BR3 are unchanged\n",
    "    #When the program adds a technical replicate, it takes the union of all of the peptide measurements between the technical replicate and the other replicate data, taking the mean for repeated measurements.\n",
    "print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the useful ways we can figure out more about the pipeline is by looking at the different structures and functions stored in it.\n",
    "#Two useful tools are help() and dir(), which can be called on any variable we create, although they're most useful for Experiments and their functions\n",
    "\n",
    "#help(exp) will list all the functions associated with exp and will include additional information about the different parameters you can set\n",
    "    #help() is kind of overwhelming if you call it on the full exp:\n",
    "help(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(exp) will list all the functions and structures associated with exp\n",
    "    #dir() is better for getting a general idea of Experiments, although it doesn't specify whether something is a function or a structure\n",
    "    #it's also best to ignore the functions of the form __blahblahblah__: you won't be calling them as an end user (they are private)\n",
    "dir(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we glance at dir, we can see that exp has a structure associated with it called experimentalReplicates. Let's try to call it:\n",
    "print(exp.experimentalReplicates)\n",
    "#it seems like a list of ExperimentalReplicate structures, in this case BR1, BR2, and BR3, although the printout is confusing and doesn't really help us do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can index the list to get just one instead:\n",
    "print(exp.experimentalReplicates[0])\n",
    "#Much better... If we compare this to print(exp), we can see that this is indeed the 1st replicate we loaded into the pipeline\n",
    "    #Python is 0-indexed\n",
    "\n",
    "#Each Experiment like exp stores MS data as separated ExperimentalReplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make things easier, instead of calling exp.experimentalReplicates[0] whenever we want the 1st replicate of an Experiment, we can just index the Experiment directly:\n",
    "print(exp[0])\n",
    "#Try to print out the 3rd replicate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also call help() and dir() on these ExperimentalReplicates directly:\n",
    "dir(exp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or on specific functions we see\n",
    "help(exp.heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At the core of each ExperimentalReplicate is just the MS data we loaded in the first place\n",
    "    #This is stored in cellData\n",
    "    #Each cell line's MS data is in a separate data structure inside of cellData\n",
    "#Let's print the 1st replicate's MS data\n",
    "print(exp[0].cellData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each replicate's cellData is a list of data structures that each store one cell line's MS data\n",
    "#here we call BR1's data on the first cell line only, 2934\n",
    "print(exp[0].cellData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try actually producing a plot now, maybe a heatmap plot as above\n",
    "exp.heatmap()\n",
    "#However, before we can generate heatmap plots, we have to merge the separate replicates to create overall peptide abundance levels for the entire Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining replicates is easy!\n",
    "exp.combineReplicates()\n",
    "print(exp)\n",
    "#Now when we print(exp), we can see the overall values for each cell line and the intersection of all of these overall cell line values\n",
    "    #When we combine replicates, we average all the available replicate abundances for each peptide: these values are used for plots like heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may notice that there is an 'n' and a 'std dev' listed with the combined replicates.\n",
    "#These are cutoffs the user can enforce to try to eliminate low-confidence peptide measurements\n",
    "    #For example, we might want to only keep peptides that show up in at least 2 replicates (>=2) and that have a small standard deviation across the replicates (<=0.2, for example)\n",
    "#If you don't specify cutoffs, the pipeline selects all peptides, even if they only show up once and even if they have a very high standard deviation across replicates\n",
    "    \n",
    "#Try to use help() to figure out how to combine the replicates with different cutoffs! You can specify both cutoffs, neither, or just one\n",
    "    #If you use n=2 and std=0.2 as the cutoffs, you should get an experimental intersection size of just 15\n",
    "    #If you use n=3 and std=0 as cutoffs, you should get a warning that there are no peptides left (no peptide exists in all 3 replicates and has a std dev of 0)\n",
    "    #If you use n=1, you should get an experimental intersection size of 421\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3A) RUN ANALYSIS - PLOTS\n",
    "\n",
    "#Now let's plot our heatmap!\n",
    "#call the function\n",
    "exp.heatmap()\n",
    "#then display the plot\n",
    "#NOTE: this is not strictly necessary when working with Jupyter Notebooks (.ipynb), but it is required when running Python (.py) files\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we look at the heatmap function, we can see that there are many different parameters we can set\n",
    "help(exp.heatmap)\n",
    "#the most useful ones are display and fileLocation, and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can save our heatmap to the default file location for our experiment instead of displaying it\n",
    "    #we set this in cell 5 to be demo/output/\n",
    "exp.heatmap(display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a critical part of the pipeline is to be able to adjust the normalization scheme when plotting or analyzing\n",
    "exp.heatmap() #default is 'refbasal' (normalize to reference cell line's basal/first time point)\n",
    "exp.heatmap(normalization='ownbasal') #normalize each cell line to its own basal/first time point\n",
    "exp.heatmap(normalization='reftime') #normalize each time point to that reference time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But what if we want to change the reference cell line?\n",
    "exp.setReference('2935')\n",
    "exp.heatmap(normalization = 'reftime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also target individual replicates directly\n",
    "exp[0].heatmap(normalization = 'reftime')\n",
    "#Notice there are a lot fewer peptide rows than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are some more plots to get started. Try playing around with the normalization and reference options, as well as the parameters for plots like volcano!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.setReference('3138')\n",
    "help(exp.heatmapToReference)\n",
    "exp.heatmapToReference(normalization='reftime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(exp.pcaToReference)\n",
    "exp.pcaToReference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(exp.pca)\n",
    "exp.pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may notice that the PCA plot doesn't look like the one I showed in group meeting, where 2937 and 3138 are together on the bottom right.\n",
    "    #That's because we are using all 3 replicates here, whereas in the plot I showed in group meeting, I had only included the first replicate.\n",
    "#Try to generate a new pca plot using only the first repicate (you may have to make a new experiment, or you can just call the function on the first replicate):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(exp.volcano)\n",
    "#NOTE: this takes a long time to run because it produces a volcano for each time point and each non-reference cell line\n",
    "# exp.volcano(display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3B) RUN ANALYSIS - FILES\n",
    "help(exp.correlationToSelf)\n",
    "#NOTE: this is a slow analysis type\n",
    "#exp.correlationToSelf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(exp.correlationToReference)\n",
    "#NOTE: this is a slow analysis type\n",
    "#exp.correlationToReference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(exp.correlationToReferenceDiagonal)\n",
    "#NOTE: this is a slow analysis type\n",
    "#exp.correlationToReferenceDiagonal()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
